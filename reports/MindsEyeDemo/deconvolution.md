First we define a forward filter, in this case a simple convolution filter emulating motion blur

Code from [MindsEyeDemo.scala:349](../../src/test/scala/MindsEyeDemo.scala#L349) executed in 0.13 seconds: 
```java
    def singleConvolution: ConvolutionSynapseLayer = {
      val convolution = new ConvolutionSynapseLayer(Array[Int](3, 3), 9)
      (0 until 3).foreach(ii⇒{
        val i = ii + ii * 3
        convolution.kernel.set(Array[Int](0, 2, i), 0.333)
        convolution.kernel.set(Array[Int](1, 1, i), 0.333)
        convolution.kernel.set(Array[Int](2, 0, i), 0.333)
      })
      convolution.freeze
      convolution
    }
    val net = new DAGNetwork
    net.add(singleConvolution)
    net.add(singleConvolution)
    net.add(singleConvolution)
    net
```

Returns: 

```
    {
      "class": "DAGNetwork",
      "id": "bda0cb2d-e331-453b-937e-ddad0000002b",
      "root": {
        "layer": {
          "class": "ConvolutionSynapseLayer",
          "id": "bda0cb2d-e331-453b-937e-ddad0000002e",
          "kernel": "[ [ [ 0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0 ],[ 0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0 ],[ 0.333,0.0,0.0,0.0,0.333,0.0,0.0,0.0,0.333 ] ],[ [ 0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0 ],[ 0.333,0.0,0.0,0.0,0.333,0.0,0.0,0.0,0.333 ],[ 0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0 ] ],[ [ 0.333,0.0,0.0,0.0,0.333,0.0,0.0,0.0,0.333 ],[ 0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0 ],[ 0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0 ] ] ]"
        },
        "prev0": {
          "layer": {
            "class": "ConvolutionSynapseLayer",
            "id": "bda0cb2d-e331-453b-937e-ddad0000002d",
            "kernel": "[ [ [ 0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0 ],[ 0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0 ],[ 0.333,0.0,0.0,0.0,0.333,0.0,0.0,0.0,0.333 ] ],[ [ 0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0 ],[ 0.333,0.0,0.0,0.0,0.333,0.0,0.0,0.0,0.333 ],[ 0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0 ] ],[ [ 0.333,0.0,0.0,0.0,0.333,0.0,0.0,0.0,0.333 ],[ 0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0 ],[ 0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0 ] ] ]"
          },
          "prev0": {
            "layer": {
              "class": "ConvolutionSynapseLayer",
              "id": "bda0cb2d-e331-453b-937e-ddad0000002c",
              "kernel": "[ [ [ 0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0 ],[ 0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0 ],[ 0.333,0.0,0.0,0.0,0.333,0.0,0.0,0.0,0.333 ] ],[ [ 0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0 ],[ 0.333,0.0,0.0,0.0,0.333,0.0,0.0,0.0,0.333 ],[ 0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0 ] ],[ [ 0.333,0.0,0.0,0.0,0.333,0.0,0.0,0.0,0.333 ],[ 0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0 ],[ 0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0 ] ] ]"
            },
            "prev0": {
              "target": "[775b66ba-bb0a-4213-8bdb-efcb96f74b00, f14bdb81-d439-491d-92f1-beca5f828db5]"
            }
          }
        }
      }
    }
```



We load an ideal training image, which we will try to reconstruct: 

Code from [MindsEyeDemo.scala:369](../../src/test/scala/MindsEyeDemo.scala#L369) executed in 0.52 seconds: 
```java
    val read = ImageIO.read(getClass.getResourceAsStream("/monkey1.jpg"))
    def scale(img: BufferedImage, scale: Double) = {
      val w = img.getWidth
      val h = img.getHeight
      val after = new BufferedImage((w * scale).toInt, (h * scale).toInt, BufferedImage.TYPE_INT_ARGB)
      val at = new AffineTransform
      at.scale(scale, scale)
      new AffineTransformOp(at, AffineTransformOp.TYPE_BILINEAR).filter(img, after)
    }
    scale(read, 0.5)
```

Returns: 

![Result](deconvolution.1.png)



Next we run this ideal image through our constructed filter to create a blurred image: 

Code from [MindsEyeDemo.scala:384](../../src/test/scala/MindsEyeDemo.scala#L384) executed in 1.62 seconds: 
```java
    blurFilter.eval(Array(Array(idealImageTensor))).data.head
```

Returns: 

```
    [ [ [ 91.42886761200002,184.11322048200003,138.251082528 ],[ 93.38594757300001,184.96251933300005,141.53749982100004 ],[ 91.20731139000002,182.93158729800004,141.16823945100003 ],[ 90.24723442800001,182.78388315,141.75905604300002 ],[ 88.62248880000003,183.15314352000001,141.90676019100002 ],[ 86.37000054300002,183.37469974200005,141.574425858 ],[ 84.00673417500002,183.116217483,141.13131341400003 ],[ 84.11751228600001,185.07329744400002,143.01454130100004 ],... ],[ [ 92.42587061100002,185.11022348100005,139.24808552700003 ],[ 90.98575516800001,183.30084766800005,139.61734589700004 ],[ 91.05960724200001,182.96851333500004,140.94668322900003 ],[ 90.35801253900001,183.11621748300004,141.79598208000002 ],[ 88.84404502200002,183.67010803800002,142.09139037600002 ],[ 86.55463072800002,183.67010803800002,141.72213000600001 ],[ 86.148444321,185.11022348100002,143.125319412 ],[ 86.03766621000003,187.06730344200002,145.00854729900004 ],... ],[ [ 90.76419894600002,184.07629444500003,137.955674232 ],[ 91.50271968600002,183.78088614900003,139.912754193 ],[ 91.68734987100001,183.96551633400003,141.79598208000002 ],[ 90.727272909,184.15014651900003,142.46065074600003 ],[ 88.88097105900002,184.26092463000003,142.34987263500003 ],[ 87.77318994900001,185.07329744400002,143.125319412 ],[ 86.88696506100003,186.36570873900004,144.38080467000003 ],[ 84.59755076700002,185.84874422100006,143.82691411500002 ],... ],[ [ 91.35501553800002,184.408628778,138.288008565 ],[ 92.20431438900002,185.07329744400002,141.31594359900004 ],[ 91.50271968600002,185.03637140700002,142.42372470900003 ],[ 90.28416046500001,184.777889148,142.60835489400003 ],[ 88.73326691100002,184.99944537000002,143.08839337500004 ],[ 86.99774317200001,185.70104007300003,143.75306204100002 ],[ 85.48377565500002,185.36870574000005,143.49457978200002 ],[ 83.12050928700002,184.92559329600005,142.68220696800003 ],... ],[ [ 91.87198005600001,185.92259629500003,140.06045834100001 ],[ 91.31808950100002,186.14415251700004,141.72213000600004 ],[ 90.35801253900001,185.22100159200002,142.12831641300002 ],[ 88.844045022,184.92559329600002,142.75605904200003 ],[ 86.37000054300002,185.14714951800005,143.23609752300004 ],[ 85.48377565500002,184.92559329600005,143.162245449 ],[ 83.78517795300002,184.26092463000003,142.276020561 ],[ 82.271210436,184.03936840800003,142.01753830200002 ],... ],[ [ 90.80112498300002,186.84574722000002,140.28201456300002 ],[ 89.73026991000002,185.66411403600003,140.90975719200003 ],[ 88.43785861500001,185.03637140700002,141.94368622800002 ],[ 85.85303602500002,184.88866725900004,142.719133005 ],[ 85.29914547000001,184.96251933300005,143.199171486 ],[ 84.11751228600002,184.11322048200003,142.34987263500003 ],[ 82.71432288000001,183.59625596400002,141.72213000600004 ],[ 81.97580214000001,183.70703407500002,141.463647747 ],... ],[ [ 89.21330539200002,185.88567025800003,139.174233453 ],[ 87.994746171,185.25792762900002,140.46664474800002 ],[ 85.88996206200001,184.99944537000005,141.86983415400002 ],[ 85.44684961800002,185.36870574000002,143.199171486 ],[ 84.56062473000001,184.66711103700004,143.014541301 ],[ 82.64047080600001,183.48547785300002,141.72213000600004 ],[ 82.45584062100001,183.15314352000004,141.168239451 ],[ 82.97280513900002,183.67010803800002,141.64827793200004 ],... ],[ [ 88.216302393,185.51640988800003,138.69419497200002 ],[ 86.81311298700001,185.47948385100003,140.61434889600002 ],[ 86.07459224700001,185.77489214700003,142.49757678300003 ],[ 85.37299754400001,185.51640988800003,143.56843185600002 ],[ 82.64047080600001,183.81781218600003,142.05446433900002 ],[ 82.197358362,182.74695711300004,140.90975719200003 ],[ 83.04665721300002,183.15314352000001,141.279017562 ],[ 83.268213435,183.48547785300002,141.57442585800004 ],... ],... ]
```



Code from [MindsEyeDemo.scala:387](../../src/test/scala/MindsEyeDemo.scala#L387) executed in 0.12 seconds: 
```java
    blurredImage.toRgbImage()
```

Returns: 

![Result](deconvolution.2.png)



Now we define a reconstruction network, which adapts a bias layer to find the source image given a post-filter image while also considering normalization factors including image entropy: 

Code from [MindsEyeDemo.scala:396](../../src/test/scala/MindsEyeDemo.scala#L396) executed in 0.01 seconds: 
```java
    val net = new DAGNetwork
    val bias = new BiasLayer(inputSize: _*)
    val modeledImageNode = net.add(bias).getHead
    net.add(blurFilter)
    net.addLossComponent(new SqLossLayer)
    val imageRMS: DAGNode = net.add(new VerboseWrapper("rms", new BiasLayer().freeze)).getHead
    net.add(new AbsActivationLayer, modeledImageNode)
    net.add(new L1NormalizationLayer)
    net.add(new EntropyLayer)
    net.add(new SumInputsLayer)
    val image_entropy: DAGNode = net.add(new VerboseWrapper("entropy", new BiasLayer().freeze)).getHead
    val scaledRms: DAGNode = net.add(new LinearActivationLayer().setWeight(1.0).freeze, imageRMS).getHead
    val scaledEntropy: DAGNode = net.add(new LinearActivationLayer().setWeight(0.001).freeze, image_entropy).getHead
    net.add(new VerboseWrapper("composite", new SumInputsLayer), scaledRms, scaledEntropy)
    (bias, net)
```

Returns: 

```
    ({
      "class": "BiasLayer",
      "id": "bda0cb2d-e331-453b-937e-ddad00000030",
      "bias": "[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0... and 4675472 more bytes
```



Code from [MindsEyeDemo.scala:468](../../src/test/scala/MindsEyeDemo.scala#L468) executed in 1.16 seconds: 
```java
    val nodes: List[DAGNode] = dagNetwork.getNodes.asScala.toList
    val graphNodes: Map[UUID, MutableNode] = nodes.map(node ⇒ {
      node.getId() → guru.nidi.graphviz.model.Factory.mutNode((node match {
        case n : InnerNode ⇒
          n.nnlayer match {
            case _ if(n.nnlayer.isInstanceOf[VerboseWrapper]) ⇒ n.nnlayer.asInstanceOf[VerboseWrapper].inner.getClass.getSimpleName
            case _ ⇒ n.nnlayer.getClass.getSimpleName
          }
        case _ ⇒ node.getClass.getSimpleName
      }) + "\n" + node.getId.toString)
    }).toMap
    val idMap: Map[UUID, List[UUID]] = nodes.flatMap((to: DAGNode) ⇒ {
      to.getInputs.map((from: DAGNode) ⇒ {
        from.getId → to.getId
      })
    }).groupBy(_._1).mapValues(_.map(_._2))
    nodes.foreach((to: DAGNode) ⇒ {
      graphNodes(to.getId).addLink(idMap.getOrElse(to.getId, List.empty).map(from ⇒ {
        Link.to(graphNodes(from))
      }): _*)
    })
    val nodeArray = graphNodes.values.map(_.asInstanceOf[LinkSource]).toArray
    val graph = guru.nidi.graphviz.model.Factory.graph().`with`(nodeArray: _*)
      .generalAttr.`with`(RankDir.TOP_TO_BOTTOM).directed()
    Graphviz.fromGraph(graph).width(width).render(Format.PNG).toImage
```

Returns: 

![Result](deconvolution.3.png)



Now we define a standard L-BFGS trainer to optimize the reconstruction

Code from [MindsEyeDemo.scala:416](../../src/test/scala/MindsEyeDemo.scala#L416) executed in 0.00 seconds: 
```java
    val gradientTrainer: LbfgsTrainer = new LbfgsTrainer
    gradientTrainer.setNet(dagNetwork)
    gradientTrainer.setData(Seq(Array(zeroInput, blurredImage)).toArray)
    new IterativeTrainer(gradientTrainer)
```

Returns: 

```
    com.simiacryptus.mindseye.training.IterativeTrainer@13464477
```



Code from [MindsEyeDemo.scala:422](../../src/test/scala/MindsEyeDemo.scala#L422) executed in 63.84 seconds: 
```java
    bias.addWeights(new DoubleSupplier {
      override def getAsDouble: Double = Util.R.get.nextGaussian * 1e-5
    })
    val trainingContext = new TrainingContext
    trainingContext.terminalErr = 0.05
    trainer.step(trainingContext)
    val finalError = trainer.step(trainingContext).finalError
    System.out.println(s"Final Error = $finalError")
```
Logging: 
```
    Final Error = 0.08763064406831315
    
```

Returns: 

```
    ()
```



Which results in the convergence timeline: 

Code from [MindsEyeDemo.scala:446](../../src/test/scala/MindsEyeDemo.scala#L446) executed in 0.00 seconds: 
```java
    val step = Math.max(Math.pow(10,Math.ceil(Math.log(history.size()) / Math.log(10))-2), 1).toInt
    TableOutput.create(history.asScala.filter(0==_.getIteration%step).map(state ⇒
      Map[String, AnyRef](
        "iteration" → state.getIteration.toInt.asInstanceOf[Integer],
        "time" → state.getEvaluationTime.toDouble.asInstanceOf[lang.Double],
        "fitness" → state.getFitness.toDouble.asInstanceOf[lang.Double]
      ).asJava
    ): _*)
```

Returns: 

iteration | time | fitness
--------- | ---- | -------
     0 | 1.2413 | 13810.4452
     1 | 5.1331 | 10185.8644
     2 | 5.6340 | 33.5556
     3 | 1.2900 | 13.1706
     4 | 1.4560 | 6.7531
     5 | 1.6056 | 3.3644
     6 | 1.8102 | 1.9962
     7 | 1.9383 | 1.3250
     8 | 2.1110 | 1.0609
     9 | 2.2759 | 0.7512
    10 | 2.4710 | 0.6075
    11 | 2.4245 | 0.4756
    12 | 2.4341 | 0.3974
    13 | 2.4300 | 0.3407
    14 | 2.6293 | 0.2965
    15 | 2.4408 | 0.2406
    16 | 2.4386 | 0.2207
    17 | 2.4324 | 0.1946
    18 | 2.4528 | 0.1738
    19 | 2.4366 | 0.1490
    20 | 2.4509 | 0.1378
    21 | 2.4452 | 0.1261
    22 | 2.4337 | 0.1142
    23 | 2.4419 | 0.1021
    24 | 2.4336 | 0.0952
    25 | 2.4641 | 0.0876




Code from [MindsEyeDemo.scala:456](../../src/test/scala/MindsEyeDemo.scala#L456) executed in 0.04 seconds: 
```java
    val plot: PlotCanvas = ScatterPlot.plot(history.asScala.map(item ⇒ Array[Double](
      item.getIteration, Math.log(item.getFitness)
    )).toArray: _*)
    plot.setTitle("Convergence Plot")
    plot.setAxisLabels("Iteration", "log(Fitness)")
    plot.setSize(600, 400)
    plot
```

Returns: 

![Result](deconvolution.4.png)



Now we query the reconstruction model for the source image: 

Code from [MindsEyeDemo.scala:436](../../src/test/scala/MindsEyeDemo.scala#L436) executed in 0.04 seconds: 
```java
    dagNetwork.getChild(bias.getId).asInstanceOf[BiasLayer].eval(zeroInput).data(0).toRgbImage()
```

Returns: 

![Result](deconvolution.5.png)



