First we define a forward filter, in this case a simple convolution filter emulating motion blur

Code from [MindsEyeDemo.scala:353](../../src/test/scala/MindsEyeDemo.scala#L353) executed in 0.16 seconds: 
```java
    def singleConvolution: ConvolutionSynapseLayer = {
      val convolution = new ConvolutionSynapseLayer(Array[Int](3, 3), 9)
      (0 until 3).foreach(ii⇒{
        val i = ii + ii * 3
        convolution.kernel.set(Array[Int](0, 2, i), 0.333)
        convolution.kernel.set(Array[Int](1, 1, i), 0.333)
        convolution.kernel.set(Array[Int](2, 0, i), 0.333)
      })
      convolution.freeze
      convolution
    }
    val net = new DAGNetwork
    net.add(singleConvolution)
    net.add(singleConvolution)
    net.add(singleConvolution)
    net
```

Returns: 

```
    {
      "class": "DAGNetwork",
      "id": "c032913e-c689-4a8c-b707-0a1c0000002b",
      "root": {
        "layer": {
          "class": "ConvolutionSynapseLayer",
          "id": "c032913e-c689-4a8c-b707-0a1c0000002e",
          "kernel": "[ [ [ 0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0 ],[ 0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0 ],[ 0.333,0.0,0.0,0.0,0.333,0.0,0.0,0.0,0.333 ] ],[ [ 0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0 ],[ 0.333,0.0,0.0,0.0,0.333,0.0,0.0,0.0,0.333 ],[ 0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0 ] ],[ [ 0.333,0.0,0.0,0.0,0.333,0.0,0.0,0.0,0.333 ],[ 0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0 ],[ 0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0 ] ] ]"
        },
        "prev0": {
          "layer": {
            "class": "ConvolutionSynapseLayer",
            "id": "c032913e-c689-4a8c-b707-0a1c0000002d",
            "kernel": "[ [ [ 0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0 ],[ 0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0 ],[ 0.333,0.0,0.0,0.0,0.333,0.0,0.0,0.0,0.333 ] ],[ [ 0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0 ],[ 0.333,0.0,0.0,0.0,0.333,0.0,0.0,0.0,0.333 ],[ 0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0 ] ],[ [ 0.333,0.0,0.0,0.0,0.333,0.0,0.0,0.0,0.333 ],[ 0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0 ],[ 0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0 ] ] ]"
          },
          "prev0": {
            "layer": {
              "class": "ConvolutionSynapseLayer",
              "id": "c032913e-c689-4a8c-b707-0a1c0000002c",
              "kernel": "[ [ [ 0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0 ],[ 0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0 ],[ 0.333,0.0,0.0,0.0,0.333,0.0,0.0,0.0,0.333 ] ],[ [ 0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0 ],[ 0.333,0.0,0.0,0.0,0.333,0.0,0.0,0.0,0.333 ],[ 0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0 ] ],[ [ 0.333,0.0,0.0,0.0,0.333,0.0,0.0,0.0,0.333 ],[ 0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0 ],[ 0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0 ] ] ]"
            },
            "prev0": {
              "target": "[f60d8d93-4145-4529-a105-b9a7ca07a502, de16957b-5020-4788-a530-1b0efa05c87d]"
            }
          }
        }
      }
    }
```



We load an ideal training image, which we will try to reconstruct: 

Code from [MindsEyeDemo.scala:373](../../src/test/scala/MindsEyeDemo.scala#L373) executed in 0.54 seconds: 
```java
    val read = ImageIO.read(getClass.getResourceAsStream("/monkey1.jpg"))
    def scale(img: BufferedImage, scale: Double) = {
      val w = img.getWidth
      val h = img.getHeight
      val after = new BufferedImage((w * scale).toInt, (h * scale).toInt, BufferedImage.TYPE_INT_ARGB)
      val at = new AffineTransform
      at.scale(scale, scale)
      new AffineTransformOp(at, AffineTransformOp.TYPE_BILINEAR).filter(img, after)
    }
    scale(read, 0.5)
```

Returns: 

![Result](deconvolution.1.png)



Next we run this ideal image through our constructed filter to create a blurred image: 

Code from [MindsEyeDemo.scala:388](../../src/test/scala/MindsEyeDemo.scala#L388) executed in 4.29 seconds: 
```java
    blurFilter.eval(Array(Array(idealImageTensor))).data.head
```

Returns: 

```
    [ [ [ 91.42886761200002,184.11322048200003,138.251082528 ],[ 93.38594757300001,184.96251933300005,141.53749982100004 ],[ 91.20731139000002,182.93158729800004,141.16823945100003 ],[ 90.24723442800001,182.78388315,141.75905604300002 ],[ 88.62248880000003,183.15314352000001,141.90676019100002 ],[ 86.37000054300002,183.37469974200005,141.574425858 ],[ 84.00673417500002,183.116217483,141.13131341400003 ],[ 84.11751228600001,185.07329744400002,143.01454130100004 ],... ],[ [ 92.42587061100002,185.11022348100005,139.24808552700003 ],[ 90.98575516800001,183.30084766800005,139.61734589700004 ],[ 91.05960724200001,182.96851333500004,140.94668322900003 ],[ 90.35801253900001,183.11621748300004,141.79598208000002 ],[ 88.84404502200002,183.67010803800002,142.09139037600002 ],[ 86.55463072800002,183.67010803800002,141.72213000600001 ],[ 86.148444321,185.11022348100002,143.125319412 ],[ 86.03766621000003,187.06730344200002,145.00854729900004 ],... ],[ [ 90.76419894600002,184.07629444500003,137.955674232 ],[ 91.50271968600002,183.78088614900003,139.912754193 ],[ 91.68734987100001,183.96551633400003,141.79598208000002 ],[ 90.727272909,184.15014651900003,142.46065074600003 ],[ 88.88097105900002,184.26092463000003,142.34987263500003 ],[ 87.77318994900001,185.07329744400002,143.125319412 ],[ 86.88696506100003,186.36570873900004,144.38080467000003 ],[ 84.59755076700002,185.84874422100006,143.82691411500002 ],... ],[ [ 91.35501553800002,184.408628778,138.288008565 ],[ 92.20431438900002,185.07329744400002,141.31594359900004 ],[ 91.50271968600002,185.03637140700002,142.42372470900003 ],[ 90.28416046500001,184.777889148,142.60835489400003 ],[ 88.73326691100002,184.99944537000002,143.08839337500004 ],[ 86.99774317200001,185.70104007300003,143.75306204100002 ],[ 85.48377565500002,185.36870574000005,143.49457978200002 ],[ 83.12050928700002,184.92559329600005,142.68220696800003 ],... ],[ [ 91.87198005600001,185.92259629500003,140.06045834100001 ],[ 91.31808950100002,186.14415251700004,141.72213000600004 ],[ 90.35801253900001,185.22100159200002,142.12831641300002 ],[ 88.844045022,184.92559329600002,142.75605904200003 ],[ 86.37000054300002,185.14714951800005,143.23609752300004 ],[ 85.48377565500002,184.92559329600005,143.162245449 ],[ 83.78517795300002,184.26092463000003,142.276020561 ],[ 82.271210436,184.03936840800003,142.01753830200002 ],... ],[ [ 90.80112498300002,186.84574722000002,140.28201456300002 ],[ 89.73026991000002,185.66411403600003,140.90975719200003 ],[ 88.43785861500001,185.03637140700002,141.94368622800002 ],[ 85.85303602500002,184.88866725900004,142.719133005 ],[ 85.29914547000001,184.96251933300005,143.199171486 ],[ 84.11751228600002,184.11322048200003,142.34987263500003 ],[ 82.71432288000001,183.59625596400002,141.72213000600004 ],[ 81.97580214000001,183.70703407500002,141.463647747 ],... ],[ [ 89.21330539200002,185.88567025800003,139.174233453 ],[ 87.994746171,185.25792762900002,140.46664474800002 ],[ 85.88996206200001,184.99944537000005,141.86983415400002 ],[ 85.44684961800002,185.36870574000002,143.199171486 ],[ 84.56062473000001,184.66711103700004,143.014541301 ],[ 82.64047080600001,183.48547785300002,141.72213000600004 ],[ 82.45584062100001,183.15314352000004,141.168239451 ],[ 82.97280513900002,183.67010803800002,141.64827793200004 ],... ],[ [ 88.216302393,185.51640988800003,138.69419497200002 ],[ 86.81311298700001,185.47948385100003,140.61434889600002 ],[ 86.07459224700001,185.77489214700003,142.49757678300003 ],[ 85.37299754400001,185.51640988800003,143.56843185600002 ],[ 82.64047080600001,183.81781218600003,142.05446433900002 ],[ 82.197358362,182.74695711300004,140.90975719200003 ],[ 83.04665721300002,183.15314352000001,141.279017562 ],[ 83.268213435,183.48547785300002,141.57442585800004 ],... ],... ]
```



Code from [MindsEyeDemo.scala:391](../../src/test/scala/MindsEyeDemo.scala#L391) executed in 0.12 seconds: 
```java
    blurredImage.toRgbImage()
```

Returns: 

![Result](deconvolution.2.png)



Now we define a reconstruction network, which adapts a bias layer to find the source image given a post-filter image while also considering normalization factors including image entropy: 

Code from [MindsEyeDemo.scala:400](../../src/test/scala/MindsEyeDemo.scala#L400) executed in 0.05 seconds: 
```java
    val net = new DAGNetwork
    val bias = new BiasLayer(inputSize: _*)
    val modeledImageNode = net.add(bias).getHead
    net.add(blurFilter)
    net.addLossComponent(new SqLossLayer)
    val imageRMS: DAGNode = net.add(new VerboseWrapper("rms", new BiasLayer().freeze)).getHead
    net.add(new AbsActivationLayer, modeledImageNode)
    net.add(new L1NormalizationLayer)
    net.add(new EntropyLayer)
    net.add(new SumInputsLayer)
    val image_entropy: DAGNode = net.add(new VerboseWrapper("entropy", new BiasLayer().freeze)).getHead
    val scaledRms: DAGNode = net.add(new LinearActivationLayer().setWeight(1.0).freeze, imageRMS).getHead
    val scaledEntropy: DAGNode = net.add(new LinearActivationLayer().setWeight(0.001).freeze, image_entropy).getHead
    net.add(new VerboseWrapper("composite", new SumInputsLayer), scaledRms, scaledEntropy)
    (bias, net)
```

Returns: 

```
    ({
      "class": "BiasLayer",
      "id": "c032913e-c689-4a8c-b707-0a1c00000030",
      "bias": "[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0... and 4675472 more bytes
```



Code from [MindsEyeDemo.scala:472](../../src/test/scala/MindsEyeDemo.scala#L472) executed in 1.11 seconds: 
```java
    val nodes: List[DAGNode] = dagNetwork.getNodes.asScala.toList
    val graphNodes: Map[UUID, MutableNode] = nodes.map(node ⇒ {
      node.getId() → guru.nidi.graphviz.model.Factory.mutNode((node match {
        case n : InnerNode ⇒
          n.nnlayer match {
            case _ if(n.nnlayer.isInstanceOf[VerboseWrapper]) ⇒ n.nnlayer.asInstanceOf[VerboseWrapper].inner.getClass.getSimpleName
            case _ ⇒ n.nnlayer.getClass.getSimpleName
          }
        case _ ⇒ node.getClass.getSimpleName
      }) + "\n" + node.getId.toString)
    }).toMap
    val idMap: Map[UUID, List[UUID]] = nodes.flatMap((to: DAGNode) ⇒ {
      to.getInputs.map((from: DAGNode) ⇒ {
        from.getId → to.getId
      })
    }).groupBy(_._1).mapValues(_.map(_._2))
    nodes.foreach((to: DAGNode) ⇒ {
      graphNodes(to.getId).addLink(idMap.getOrElse(to.getId, List.empty).map(from ⇒ {
        Link.to(graphNodes(from))
      }): _*)
    })
    val nodeArray = graphNodes.values.map(_.asInstanceOf[LinkSource]).toArray
    val graph = guru.nidi.graphviz.model.Factory.graph().`with`(nodeArray: _*)
      .generalAttr.`with`(RankDir.TOP_TO_BOTTOM).directed()
    Graphviz.fromGraph(graph).width(width).render(Format.PNG).toImage
```

Returns: 

![Result](deconvolution.3.png)



Now we define a standard L-BFGS trainer to optimize the reconstruction

Code from [MindsEyeDemo.scala:420](../../src/test/scala/MindsEyeDemo.scala#L420) executed in 0.00 seconds: 
```java
    val gradientTrainer: LbfgsTrainer = new LbfgsTrainer
    gradientTrainer.setNet(dagNetwork)
    gradientTrainer.setData(Seq(Array(zeroInput, blurredImage)).toArray)
    new IterativeTrainer(gradientTrainer)
```

Returns: 

```
    com.simiacryptus.mindseye.training.IterativeTrainer@434864a6
```



Code from [MindsEyeDemo.scala:426](../../src/test/scala/MindsEyeDemo.scala#L426) executed in 64.18 seconds: 
```java
    bias.addWeights(new DoubleSupplier {
      override def getAsDouble: Double = Util.R.get.nextGaussian * 1e-5
    })
    val trainingContext = new TrainingContext
    trainingContext.terminalErr = 0.05
    trainer.step(trainingContext)
    val finalError = trainer.step(trainingContext).finalError
    System.out.println(s"Final Error = $finalError")
```
Logging: 
```
    Final Error = 0.089197475878796
    
```

Returns: 

```
    ()
```



Which results in the convergence timeline: 

Code from [MindsEyeDemo.scala:450](../../src/test/scala/MindsEyeDemo.scala#L450) executed in 0.00 seconds: 
```java
    val step = Math.max(Math.pow(10,Math.ceil(Math.log(history.size()) / Math.log(10))-2), 1).toInt
    TableOutput.create(history.asScala.filter(0==_.getIteration%step).map(state ⇒
      Map[String, AnyRef](
        "iteration" → state.getIteration.toInt.asInstanceOf[Integer],
        "time" → state.getEvaluationTime.toDouble.asInstanceOf[lang.Double],
        "fitness" → state.getFitness.toDouble.asInstanceOf[lang.Double]
      ).asJava
    ): _*)
```

Returns: 

iteration | time | fitness
--------- | ---- | -------
     0 | 1.2802 | 13810.4450
     1 | 5.3093 | 10185.8646
     2 | 5.8485 | 33.5822
     3 | 1.3253 | 13.1532
     4 | 1.4546 | 6.7625
     5 | 1.6125 | 3.3626
     6 | 1.7824 | 1.9968
     7 | 1.9625 | 1.3255
     8 | 2.1114 | 1.0623
     9 | 2.2714 | 0.7526
    10 | 2.4419 | 0.6096
    11 | 2.4687 | 0.4777
    12 | 2.4400 | 0.3991
    13 | 2.4298 | 0.3425
    14 | 2.4488 | 0.2993
    15 | 2.4692 | 0.2416
    16 | 2.4381 | 0.2220
    17 | 2.4385 | 0.1957
    18 | 2.4595 | 0.1740
    19 | 2.4270 | 0.1495
    20 | 2.4343 | 0.1381
    21 | 2.4400 | 0.1262
    22 | 2.4554 | 0.1152
    23 | 2.4376 | 0.1032
    24 | 2.4394 | 0.0961
    25 | 2.4688 | 0.0892




Code from [MindsEyeDemo.scala:460](../../src/test/scala/MindsEyeDemo.scala#L460) executed in 0.03 seconds: 
```java
    val plot: PlotCanvas = ScatterPlot.plot(history.asScala.map(item ⇒ Array[Double](
      item.getIteration, Math.log(item.getFitness)
    )).toArray: _*)
    plot.setTitle("Convergence Plot")
    plot.setAxisLabels("Iteration", "log(Fitness)")
    plot.setSize(600, 400)
    plot
```

Returns: 

![Result](deconvolution.4.png)



Now we query the reconstruction model for the source image: 

Code from [MindsEyeDemo.scala:440](../../src/test/scala/MindsEyeDemo.scala#L440) executed in 0.04 seconds: 
```java
    dagNetwork.getChild(bias.getId).asInstanceOf[BiasLayer].eval(zeroInput).data(0).toRgbImage()
```

Returns: 

![Result](deconvolution.5.png)



